services:
  envmodel_gpu:
    profiles: ["miner","gpu"]
#    build: .
    image:  h4ckermike/petals:main
    environment:
      - MAX_DISK_SPACE=${MAX_DISK_SPACE}
      - PUBLIC_NAME=${PUBLIC_NAME}
      - MODEL=${MODEL}
      - INITIAL_PEERS=${INITIAL_PEERS}
      - DEVICE=${DEVICE}
      - BLOCKS=${BLOCKS}
      - PORT=${PORT}
    command: python -m petals.cli.run_server --port ${PORT}  --num_blocks=$BLOCKS  $MODEL  --initial_peers $INITIAL_PEERS  --device=$DEVICE

    ports:
      - "$PORT:$PORT"
    restart: always
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
volumes:
  petals-cache-backbone:
